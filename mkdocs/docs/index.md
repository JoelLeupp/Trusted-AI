# Trusted AI Master Project 

This site serves as documentation and Overview of the Master Project.

## Introduction

Artificial intelligence (AI) systems are getting more and more relevance as support to
human decision-making processes. While AI holds the promise of delivering valuable insights
into many application scenarios, the broad adoption of AI systems will rely on the ability to
trust their decisions. According to IBM, some key aspects provide information to trust (or not)
a decision made by an algorithm. In particular, a decision must: be reliable and fair, be
accounted for, not cause harm, not be tampered with, be understandable, and be
secure. In this context, the previous aspects have been grouped into the following pillars.

• Fairness. One of the essential aspects to enable trusted AI is to avoid bias across
the entire lifecycle of AI applications, as well as across different bias and data types.

• Robustness. AI-based systems may be vulnerable to adversarial attacks. Attackers
may poison training data by injecting samples to compromise system decisions eventually.

• Explainability. In many application scenarios, decisions made by algorithms must be
explainable and understandable by humans. Various stakeholders require explanations for
different purposes, and explanations must be tailored to their needs.

• Accountability. The quality of decisions should be evaluated in terms of accuracy,
ability to satisfy users’ preferences, as well as other properties related to the impact of the
decision.The previous characteristics are demanded from AI systems. Yet, to achieve trust in AI, more
efforts and automatic mechanisms able to calculate and communicate trust levels are required.
