{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc778f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import statistics\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f2d78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get inputs\n",
    "def get_case_inputs(case):\n",
    "    scenario_path = os.path.join(\"Validation\", case)\n",
    "\n",
    "    with open(os.path.join(scenario_path, \"factsheet.txt\")) as file:\n",
    "        factsheet = json.load(file)\n",
    "        \n",
    "    with open(os.path.join(scenario_path, \"model.sav\"),'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    with open(os.path.join(scenario_path, \"X_test.pkl\"),'rb') as file:\n",
    "        X_test = pickle.load(file)\n",
    "\n",
    "    with open(os.path.join(scenario_path, \"X_train.pkl\"),'rb') as file:\n",
    "        X_train = pickle.load(file)\n",
    "\n",
    "    with open(os.path.join(scenario_path, \"y_test.pkl\"),'rb') as file:\n",
    "        y_test = pickle.load(file)\n",
    "\n",
    "    with open(os.path.join(scenario_path, \"y_train.pkl\"),'rb') as file:\n",
    "        y_train = pickle.load(file)\n",
    "\n",
    "    return [factsheet, model, X_test, X_train, y_test, y_train]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e92efbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model inputs\n",
    "\n",
    "# choose scenario case (case1,case1,..)\n",
    "case = \"case1\"\n",
    "\n",
    "# load case inputs\n",
    "factsheet, model, X_test, X_train, y_test, y_train = get_case_inputs(case)\n",
    "\n",
    "# algo config (load from config file in the future)\n",
    "config = {\n",
    "  \"fairness\": {\n",
    "    \"par1\": 0,\n",
    "    \"par2\": 0\n",
    "  },\n",
    "  \"explainability\": {\n",
    "    \"par1\": 0,\n",
    "    \"par2\": 0\n",
    "  },\n",
    "  \"robustness\": {\n",
    "    \"par1\": 0,\n",
    "    \"par2\": 0\n",
    "  },\n",
    "  \"methodology\": {\n",
    "    \"par1\": 0,\n",
    "    \"par2\": 0\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0165e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for fairness score\n",
    "\n",
    "def score_Statistical_Parity():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def score_Disparate_Mistreatment():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def score_Class_Imbalance():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def score_Biased_Data():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def calc_fairness_score():\n",
    "    \n",
    "    output = dict(\n",
    "        Statistical_Parity     = score_Statistical_Parity(),\n",
    "        Disparate_Mistreatment = score_Disparate_Mistreatment(),\n",
    "        Class_Imbalance        = score_Class_Imbalance(),\n",
    "        Biased_Data            = score_Biased_Data()\n",
    "                 )\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29aaec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for explainability score\n",
    "\n",
    "def score_Algorithm_Class():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def score_Correlated_Features():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def score_Model_Size():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def score_Feature_Relevance():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def calc_explainability_score():\n",
    "    \n",
    "    output = dict(\n",
    "        Algorithm_Class          = score_Algorithm_Class(),\n",
    "        Correlated_Features = score_Correlated_Features(),\n",
    "        Model_Size          = score_Model_Size(),\n",
    "        Feature_Relevance   = score_Feature_Relevance()\n",
    "                 )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb27526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for robustness score\n",
    "\n",
    "def score_Confidence_Score():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def score_Class_Specific_Metrics():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def calc_robustness_score():\n",
    "    \n",
    "    output = dict(\n",
    "        Algorithm_Class          = score_Confidence_Score(),\n",
    "        Class_Specific_Metrics   = score_Class_Specific_Metrics()\n",
    "                 )\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "573404d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for methodology score\n",
    "\n",
    "def score_Normalization():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def score_Test_F1_score():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def score_Train_Test_Split():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def score_Regularization():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def score_Test_Accuracy():\n",
    "    return np.random.randint(1,4)\n",
    "\n",
    "def calc_methodology_score():\n",
    "    \n",
    "    output = dict(\n",
    "        Normalization    = score_Normalization(),\n",
    "        Test_F1_score    = score_Test_F1_score(),\n",
    "        Train_Test_Split = score_Train_Test_Split(),\n",
    "        Regularization   = score_Regularization(),\n",
    "        Test_Accuracy    = score_Test_Accuracy()\n",
    "                 )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ef64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define algo\n",
    "def trusting_AI_score "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
