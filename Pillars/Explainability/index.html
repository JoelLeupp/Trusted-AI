<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Explainability - Trused AI</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../css/theme.css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Explainability";
    var mkdocs_page_input_path = "Pillars/Explainability.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Trused AI</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Pillars</span></p>
                <ul class="current">
                    <li class="toctree-l1"><a class="reference internal" href="../Fairness/">Fairness</a>
                    </li>
                    <li class="toctree-l1 current"><a class="reference internal current" href="./">Explainability</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#summary">Summary</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#sources">sources</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#websites">Websites</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#papers">Papers</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#videos">Videos</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#taxonomy">Taxonomy</a>
    </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../Robustness/">Robustness</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../Accountability/">Accountability</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Code</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../AI_algo/">trusted AI algorithm</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../code_documentation/">Implementation</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">References</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../sources/">sources</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Trused AI</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Pillars &raquo;</li>
        
      
    
    <li>Explainability</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="explainability">Explainability</h1>
<h2 id="summary">Summary</h2>
<p>In many applications, trust in an AI system will come from its ability to ‘explain itself.’ Yet, when it comes to understanding and explaining the inner workings of an algorithm, one size does not fit all. Different stakeholders require explanations for different purposes and objectives, and explanations must be tailored to their needs. A physician might respond best to seeing examples of patient data similar to their patient’s. On the other hand, a developer training a neural net will benefit from seeing how information flows through the algorithm. While a regulator will aim to understand the system as a whole and probe into its logic, consumers affected by a specific decision will be interested only in factors impacting their case – for example, in a loan processing application, they will expect an explanation for why the request was denied and want to understand what changes could lead to approval. IBM Research is creating diverse explanations, including training highly optimized directly interpretable models, creating contrastive explanations of black box models, using information flow in a high-performing complex model to train simpler, interpretable classifiers, learning disentangled representations, and visualizing information flows in neural networks.</p>
<h2 id="sources">sources</h2>
<h3 id="websites">Websites</h3>
<ul>
<li>
<p>IBM explainability: <a href="https://www.research.ibm.com/artificial-intelligence/trusted-ai/#">explainability main page</a></p>
</li>
<li>
<p>AI Explainability 360: <a href="http://aix360-dev.mybluemix.net/?_ga=2.110848204.832936263.1613641869-1548554030.1611998814">Toolkit page</a></p>
</li>
<li>
<p>AI Explainability GitHub repo: <a href="https://github.com/Trusted-AI/AIX360">AIX360</a></p>
</li>
</ul>
<h3 id="papers">Papers</h3>
<ul>
<li>
<p>towards Robust Interpretability <a href="https://papers.nips.cc/paper/2018/file/3e9f0fc9b2f89e043bc6233994dfcf76-Paper.pdf">paper</a></p>
</li>
<li>
<p>Generating Contrastive Explanations withMonotonic Attribute Functions <a href="https://arxiv.org/pdf/1905.12698.pdf">paper</a></p>
</li>
</ul>
<h3 id="videos">Videos</h3>
<h2 id="taxonomy">Taxonomy</h2>
<p>Construct a set of measurable metrict which can be used to calculate a score that should indicate how good the explainability of a model is. For The calculation of the score differnt weights can be assigned to the metrics. </p>
<style>
table {
    width:100%;
}
</style>

<table>
<thead>
<tr>
<th>metric</th>
<th align="center">description</th>
<th>unit</th>
<th>weight</th>
</tr>
</thead>
<tbody>
<tr>
<td>model type</td>
<td align="center">some models like linear regression or<br> decision tree are very explainable and<br>models like neural networks rather not</td>
<td>boolean)</td>
<td>0.6</td>
</tr>
<tr>
<td>faithfulness<br>relevance</td>
<td align="center">are the features truly relevant<br>or can some be omitted?</td>
<td>[0,1]</td>
<td>0.2</td>
</tr>
<tr>
<td>monotonicity</td>
<td align="center">monotonic attribute functions<br>most important feature for classification</td>
<td>[-1,1]</td>
<td>0.2</td>
</tr>
</tbody>
</table>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../Robustness/" class="btn btn-neutral float-right" title="Robustness">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../Fairness/" class="btn btn-neutral" title="Fairness"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../Fairness/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../Robustness/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
