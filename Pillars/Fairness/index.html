<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Fairness - Trused AI</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../css/theme.css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Fairness";
    var mkdocs_page_input_path = "Pillars/Fairness.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Trused AI</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Pillars</span></p>
                <ul class="current">
                    <li class="toctree-l1 current"><a class="reference internal current" href="./">Fairness</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#definition-of-fairness">Definition of Fairness</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#_1"></a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#legally-recognized-protected-classes">Legally recognized 'protected classes'</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#application-examples">Application Examples</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#examples-of-algorithmic-unfairness">Examples of Algorithmic Unfairness</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#fairness-metrics">Fairness Metrics</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#1-disparate-treatment">1. Disparate Treatment</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#2-disparate-impact">2. Disparate Impact</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#3-statistical-parity">3. Statistical Parity</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#summaries-of-paper-website">Summaries of Paper &amp; Website</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#taxonomy">Taxonomy</a>
    </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../Explainability/">Explainability</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../Robustness/">Robustness</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../Accountability/">Accountability</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Code</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../AI_algo/">trusted AI algorithm</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../code_documentation/">Implementation</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">References</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../sources/">sources</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Trused AI</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Pillars &raquo;</li>
        
      
    
    <li>Fairness</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="fairness">Fairness</h1>
<h2 id="introduction">Introduction</h2>
<p>An increasing number of information systems take decisions based on statistical inference rules, acquired through machine learning techniques. Especially in decision-critical contexts such as predictive policing, lending decisions in credit scoring or triage and allocation of health care resources discrimination is to be avoided. In order to avoid encoding discrimination in automated decisions, multiple fairness aspects needs to be accounted for.</p>
<h2 id="definition-of-fairness">Definition of Fairness</h2>
<p>equal in outcomes</p>
<h3 id="_1"></h3>
<p><img alt="test" src="../images/fairness-01.png" /></p>
<h2 id="legally-recognized-protected-classes">Legally recognized 'protected classes'</h2>
<p>Depending on the context the stakeholders need to decide during the model creation process which systemic difference between groups should be available to the model and which should be excluded. These sensitive features should either not be used or very carefully, since they are protected by law.</p>
<ul>
<li>Race (Civil Rights Act of 1964)</li>
<li>Color (Civil Rights Act of 1964)</li>
<li>Sex (Equal Pay Act of 1963; Civil Rights Act of 1964)</li>
<li>Religion (Civil Rights Act of 1964)</li>
<li>National Origin (Civil Rights Act of 1964)</li>
<li>Citizenship (Immigration Reform and Control Act)</li>
<li>Age (Age Discrimination in Employment Act of 1967)</li>
<li>Pregnancy (Pregnancy Discrimination Act)</li>
<li>Family Status (Civil Rights Act of 1968)</li>
<li>Disability Status (Rehabilitation Act of 1973; Americans with Disabilities Act of 1990)</li>
<li>Veteran Status (Vietnam Era Veterans Readjustment Assistance Act of 1974)</li>
<li>Genetic Information (Genetic Information Nondiscrimination Act)</li>
<li>Sexual orientation (in some jurisdications)</li>
</ul>
<h2 id="application-examples">Application Examples</h2>
<ol>
<li><strong>Medical Testing and Diagnosis</strong><ul>
<li>Making decisions about a patient’s treatment may rely on tests providing probability estimates for different diseases and conditions.</li>
<li>Here too we can ask whether such decision-making is being applied uniformly across different groups of patients.</li>
</ul>
</li>
<li><strong>Hiring</strong></li>
<li><strong>Lending</strong></li>
<li><strong>School Admission</strong></li>
<li><strong>Criminal Justice</strong></li>
</ol>
<h2 id="examples-of-algorithmic-unfairness">Examples of Algorithmic Unfairness</h2>
<ol>
<li><strong>COMPAS risk tool</strong><ul>
<li>Assess a defendant’s probability of recidivism.</li>
<li>Tool’s errors were asymmetric: African-American defendants were more likely to be incorrectly labeled as higher-risk than they actually were, while white defendants were more likely to be incorrectly labeled as lower-risk than they actually were.</li>
<li>White defendants who went on to commit future crimes were assigned risk scores corresponding to lower probability estimates in aggregate.</li>
</ul>
</li>
<li><strong>Apple Credit Card</strong><ul>
<li>Apple Card's Credit Scoring Algorithm was investigated after discriminating against women.</li>
</ul>
</li>
</ol>
<h2 id="fairness-metrics">Fairness Metrics</h2>
<p>(1) and (2) are widely used ideas inspired by anti-discrimnation legislation</p>
<h3 id="1-disparate-treatment">1. Disparate Treatment</h3>
<p>A practice that intentionally disadvantages/discriminates a group based on a protected feature (<em>e.g the pay difference between men and women at the same position, </em>). The treatment or process should not depend on sensitive group membership.</p>
<p><strong>How to check for Disparate Treatment</strong><br />
Depending on the context certain attributes are considered to be protected. For hiring decisions in Germany for example the exmployer is not allowed to use certain information e.g (pregnancy status, wish for a child, relationship status). The user of our tool could be presented with all attributes the model is taking into consideration. He could then select every attribute he would consider in this context. On the other hand side it would be possible to define a default list of protected attributes (gender, religion, race) and let their use negatively influence the fairness score.</p>
<h3 id="2-disparate-impact">2. Disparate Impact</h3>
<p>Is what occurs when an organization’s actions, policies, or some other aspect of their processes inadvertently result in unintentional discrimination against people who are in a protected class. Even though the policy, action, or item in question would otherwise appear to be neutral. What matters is the outcome, not the intent.</p>
<p><strong>How to check for Disparate Impact</strong>  </p>
<h3 id="3-statistical-parity">3. Statistical Parity</h3>
<p>In some cases statistical parity is a central goal (and in some it is legally mandated). Statistical parity, ensures that the overall proportion of members in a protected group receiving positive (negative) classification are identical to the proportion of the population as a whole.</p>
<h2 id="summaries-of-paper-website">Summaries of Paper &amp; Website</h2>
<table>
<thead>
<tr>
<th>year</th>
<th align="center">author</th>
<th>title</th>
<th>content</th>
</tr>
</thead>
<tbody>
<tr>
<td>2016</td>
<td align="center">John Kleinberg</td>
<td>Inherent Trade-Offs in the Fair Determination of Risk Scores</td>
<td>.</td>
</tr>
<tr>
<td></td>
<td align="center"></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td align="center"></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="taxonomy">Taxonomy</h2>
<table>
<thead>
<tr>
<th>metric</th>
<th align="center">description</th>
<th>unit</th>
<th>weight</th>
</tr>
</thead>
<tbody>
<tr>
<td>Disparate Treatment</td>
<td align="center">Depending on the context certain features (gender, religion, race) are considered to be protected. Does the model take</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Disparate Impact</td>
<td align="center"></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td align="center"></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../Explainability/" class="btn btn-neutral float-right" title="Explainability">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../.." class="btn btn-neutral" title="Home"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../.." style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../Explainability/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
