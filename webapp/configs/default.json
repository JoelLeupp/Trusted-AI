{
    "fairness": {
        "parameters": {
            "score_Statistical_Parity": {
                "parameter_XY": {
                    "value": "The value of the parameter_XY",
                    "description": "The description of the paramter and its impact"
                }
            }
        },
        "weights": {
            "Statistical_Parity": 0.17,
            "Disparate_Mistreatment": 0.17,
            "Class_Imbalance": 0.17,
            "Biased_Data": 0.17,
            "Disparate_Treatment": 0.17,
            "Disparate_Impact": 0.17
        }
    },
    "explainability": {
        "parameters": {
            "score_Algorithm_Class": {
                "clf_type_score": {
                    "value": {
                        "RandomForestClassifier": 3,
                        "KNeighborsClassifier": 3,
                        "SVC": 2,
                        "GaussianProcessClassifier": 3,
                        "DecisionTreeClassifier": 4,
                        "MLPClassifier": 1,
                        "AdaBoostClassifier": 3,
                        "GaussianNB": 3.5,
                        "QuadraticDiscriminantAnalysis": 3,
                        "LogisticRegression": 3,
                        "LinearRegression": 3.5
                    },
                    "description": "Mapping of Learning techniques to the level of explainability based on on literature research and qualitative analysis of each learning technique. For more information see gh-pages/explainability/taxonomy",
                    "label": "Score Mapping"
                }
            },
            "score_Model_Size": {
                "thresholds": {
                    "value": [
                        10,
                        30,
                        100,
                        500
                    ],
                    "description": "Thresholds of how to map model size to a score from 1-5. Example if 10 is the first number it means that a model with 10 or less features would get the best score(5) and if 500 was the last number it would mean that a model with 500 or more features would get the worst score (1), analog for the numbers in between",
                    "label": "Score Thresholds"
                }
            },
            "score_Correlated_Features": {
                "thresholds": {
                    "value": [
                        0.05,
                        0.15,
                        0.25,
                        0.4
                    ],
                    "description": "Thresholds of how to map the percentage of highly correlated features (>=0.95) to a score from 1-5. Example if 0.05 is the first number it means that training dataset with 5% or less highly correlated variables would get the best score(5) and if 0.4 was the last number it would mean that a training dataset 40% or more highly correlated features would get the worst score (1), analog for the numbers in between",
                    "label": "Score Thresholds"
                }
            },
            "score_Feature_Relevance": {
                "thresholds": {
                    "value": [
                        0.05,
                        0.1,
                        0.2,
                        0.3
                    ],
                    "description": "Map the fraction of many features make up 60% of all importance to a Score from 1-5. If the first number in the list is 0.05 it means that 5% or less features make up more than 60% of all importance, which would be a very skewed distribution of the feature importance and result in the worst score of 1, and if the next number is 0.1 it means if the fraction is between 5%-10% the Score would be a 2, analog the other thresholds",
                    "label": "Score Thresholds"
                },
                "threshold_outlier": {
                    "value": 0.03,
                    "description": "The threshold for a score penalty if there are too many outliers in the feature importance distribution. For example if the threshold is 0.03 it means taht if 3% or more features are outliers a penalty with tha value #penalty_outlier would be substacted from the score",
                    "label": "Threshold for outliers"
                },
                "penalty_outlier": {
                    "value": 0.5,
                    "description": "The penalty that should be applied if the the number of outliers in the feature importance distribution is equal or greater than the #threshold_outlier. For example if this value is 0.5 it would mean if the the theshold is reached 0.5 points will be substacted from score. If the number is set to 0 no penalty will be applied",
                    "label": "Penalty for outliers"
                }
            }
        },
        "weights": {
            "Algorithm_Class": 0.55,
            "Correlated_Features": 0.15,
            "Model_Size": 0.15,
            "Feature_Relevance": 0.15
        }
    },
    "robustness": {
        "parameters": {
            "score_Confidence_Score": {
                "parameter_XY": {
                    "value": "The value of the parameter_XY",
                    "description": "The description of the paramter and its impact"
                }
            }
        },
        "weights": {
            "Confidence_Score": 0.2,
            "Clique_Method": 0.2,
            "Loss_Sensitivity": 0.2,
            "CLEVER_Score": 0.2,
            "Empirical_Robustness_Fast_Gradient_Attack": 0.2,
            "Empirical_Robustness_Carlini_Wagner_Attack": 0.2,
            "Empirical_Robustness_Deepfool_Attack": 0.2
        }
    },
    "methodology": {
        "parameters": {
            "score_Normalization": {
                "parameter_XY": {
                    "value": "The value of the parameter_XY",
                    "description": "The description of the paramter and its impact"
                }
            }
        },
        "weights": {
            "Normalization": 0.17,
            "Treatment_of_Corrupt_Values": 0.17,
            "Train_Test_Split": 0.17,
            "Regularization": 0.17,
            "Treatment_of_Categorical_Features": 0.17,
            "Feature_Filtering": 0.17
        }
    },
    "pillars": {
        "fairness": 0.25,
        "explainability": 0.25,
        "robustness": 0.25,
        "methodology": 0.25
    }
}